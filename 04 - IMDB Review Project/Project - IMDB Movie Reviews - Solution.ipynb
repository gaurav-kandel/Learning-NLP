{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115229f7",
   "metadata": {},
   "source": [
    "In this project, you will have the opportunity to delve into the realm of movie reviews by analyzing a dataset sourced from the renowned `IMDB` database. Building upon the comprehensive knowledge and tools offered by the NLTK (Natural Language Toolkit) stack, which we have extensively covered in the preceding section, you will apply these skills in a practical real-life context.\n",
    "<br>\n",
    "<br>\n",
    "Your primary objective will be to explore the movie reviews dataset, which consists of a vast collection of textual reviews provided by users on the `IMDB` platform. By leveraging the power of the NLTK stack, you will employ a range of natural language processing techniques to extract valuable insights from the reviews.\n",
    "\n",
    "To begin with, you will preprocess the raw textual data, implementing essential steps such as tokenization, removing stop words, and performing stemming or lemmatization. This process will help transform the reviews into a more structured and manageable format, enabling further analysis.\n",
    "<br>\n",
    "<br>\n",
    "**By the end of the project, you will have gained invaluable experience in working with textual data, honed your natural language processing skills, and developed a solid understanding of how the NLTK stack can be effectively applied in real-life scenarios, particularly in the realm of movie reviews.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7776c0f",
   "metadata": {},
   "source": [
    "### Project - Analyzing Movie Reviews using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808148a",
   "metadata": {},
   "source": [
    "![imdb](https://upload.wikimedia.org/wikipedia/commons/6/69/IMDB_Logo_2016.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c14ef",
   "metadata": {},
   "source": [
    "# NLTK Adventures: Unleashing the Film Review Analyzer!\n",
    "\n",
    "You find yourself in a whimsical world where IMDb has enlisted your extraordinary skills as a Text Movie Review Analyst! Picture yourself entering the majestic office of your quirky boss, Mr. Cinema, a quircky boss with a passion for cinema. He eagerly awaits your presentation on how NLTK will revolutionize their movie review analysis.\n",
    "<br>\n",
    "<br>\n",
    "Your boss wants you to analyze a large chunk of movie reviews using `nltk`. He just heard about something called `text mining` and is super eager to try using Python to analyze user reviews for the first time!\n",
    "<br>\n",
    "<br>\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bcd50c",
   "metadata": {},
   "source": [
    "Load the `IMDB Dataset.csv` file using the `pandas` module. \n",
    "<br>\n",
    "*Hint: Check the `pandas.csv` function!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a05d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "imdb_data = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d77669a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcdcb2",
   "metadata": {},
   "source": [
    "Subset the `review` column and store it in a variable called `reviews`.\n",
    "<br>\n",
    "*Hint: Check how to select columns in pandas!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6987b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = imdb_data.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd48bf80",
   "metadata": {},
   "source": [
    "Transform the reviews object into a list of reviews. Each element in the list should contain a review. Name the new object `list_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc48fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\",\n",
       " 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_reviews = list(reviews)\n",
    "list_reviews[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd37936",
   "metadata": {},
   "source": [
    "Tokenize every review on the `list_reviews` into words. Save the new object (a new list) as `tokenized_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28a0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenized_reviews = [nltk.tokenize.word_tokenize(review) for review in list_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cc7884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15800ffe",
   "metadata": {},
   "source": [
    "Perform token cleaning on every review of the list review, namely:\n",
    "- Remove stop words\n",
    "- lower case every word\n",
    "- remove punctuation.\n",
    "<br>\n",
    "You can save the cleaned tokens in a new object `cleaned_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9215f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "punctuation = string.punctuation\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "cleaned_tokens = []\n",
    "\n",
    "for review in tokenized_reviews:\n",
    "    cleaned_review = []\n",
    "    for word in review:\n",
    "        if word.lower() in punctuation or word.lower() in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_review.append(word.lower())\n",
    "    # Append Review to the cleaned_tokens object\n",
    "    cleaned_tokens.append(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b26886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you 'll be hooked . They are right , as this is exactly what happened with me. < br / > < br / > The first thing that struck me about Oz was its brutality and unflinching scenes of violence , which set in right from the word GO . Trust me , this is not a show for the faint hearted or timid . This show pulls no punches with regards to drugs , sex or violence . Its is hardcore , in the classic use of the word. < br / > < br / > It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary . It focuses mainly on Emerald City , an experimental section of the prison where all the cells have glass fronts and face inwards , so privacy is not high on the agenda . Em City is home to many .. Aryans , Muslims , gangstas , Latinos , Christians , Italians , Irish and more .... so scuffles , death stares , dodgy dealings and shady agreements are never far away. < br / > < br / > I would say the main appeal of the show is due to the fact that it goes where other shows would n't dare . Forget pretty pictures painted for mainstream audiences , forget charm , forget romance ... OZ does n't mess around . The first episode I ever saw struck me as so nasty it was surreal , I could n't say I was ready for it , but as I watched more , I developed a taste for Oz , and got accustomed to the high levels of graphic violence . Not just violence , but injustice ( crooked guards who 'll be sold out for a nickel , inmates who 'll kill on order and get away with it , well mannered , middle class inmates being turned into prison bitches due to their lack of street skills or prison experience ) Watching Oz , you may become comfortable with what is uncomfortable viewing .... thats if you can get in touch with your darker side .\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokenized_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a34d2f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one reviewers mentioned watching 1 oz episode 'll hooked right exactly happened me. br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word. br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many .. aryans muslims gangstas latinos christians italians irish .... scuffles death stares dodgy dealings shady agreements never far away. br br would say main appeal show due fact goes shows would n't dare forget pretty pictures painted mainstream audiences forget charm forget romance ... oz n't mess around first episode ever saw struck nasty surreal could n't say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards 'll sold nickel inmates 'll kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing .... thats get touch darker side\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(cleaned_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecbc56",
   "metadata": {},
   "source": [
    "Check the most common tokens of the 81th review (80th index). Which movie may it refer to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382b3cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oz', 6),\n",
       " ('br', 6),\n",
       " ('violence', 4),\n",
       " (\"'ll\", 3),\n",
       " ('show', 3),\n",
       " ('prison', 3),\n",
       " (\"n't\", 3),\n",
       " ('forget', 3),\n",
       " ('watching', 2),\n",
       " ('episode', 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(cleaned_tokens[0]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412879bf",
   "metadata": {},
   "source": [
    "Check the top 10 words of the entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecaaee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words = []\n",
    "\n",
    "for review in cleaned_tokens:\n",
    "    for word in review:\n",
    "        bag_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e95582fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6524613"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5124adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('br', 201951),\n",
       " (\"'s\", 122131),\n",
       " ('movie', 85070),\n",
       " ('film', 76919),\n",
       " (\"''\", 66435),\n",
       " (\"n't\", 66244),\n",
       " ('``', 65695),\n",
       " ('one', 51828),\n",
       " ('like', 39183),\n",
       " ('good', 28767)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FreqDist(bag_words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe03c4",
   "metadata": {},
   "source": [
    "Use a `pos_tag` to produce a version of the tokens with the respective POS_TAG. Use the off-the-shelf version of `nltk` and only tag the first 10000 reviews.\n",
    "<br>\n",
    "Name the new list of reviews with part-of-speech tags `tagged_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9271c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_reviews = [nltk.tag.pos_tag(review) for review in cleaned_tokens[0:10000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84727db7",
   "metadata": {},
   "source": [
    "Based on the `tagged_reviews` object, create a new list of lists called `adjectives` where you will have a list of every adjective per review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24686e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = []\n",
    "for review in tagged_reviews:\n",
    "    adj_review = []\n",
    "    for word_tag in review:\n",
    "        if word_tag[1].startswith('JJ'):\n",
    "            adj_review.append(word_tag[0])\n",
    "    adjectives.append(adj_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50039f48",
   "metadata": {},
   "source": [
    "Based on the column `sentiment` of the dataframe `imdb_data`, split the `adjectives` list into two lists: `adjectives_positive` and `adjectives_negative`. The `adjectives_positive` should contain be a list (not a list of lists) with all adjectives that are tied to positive reviews. The adjective negative should be a similar list with all adjectives that are tied to negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e72fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjectives_sentiment(adjectives, sentiment_column, sentiment):\n",
    "    sentiment_list = []\n",
    "    for index, adjectives_review in enumerate(adjectives):\n",
    "        if sentiment_column[index] == sentiment:\n",
    "            sentiment_list.extend(adjectives_review)\n",
    "    return sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "040c2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_positive = get_adjectives_sentiment(adjectives, imdb_data.sentiment, 'positive')\n",
    "adjectives_negative = get_adjectives_sentiment(adjectives, imdb_data.sentiment, 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654c133",
   "metadata": {},
   "source": [
    "Extract the top 50 common adjectives for negative and positive reviews. Save them in a dataframe with the number of times each adjective appears in positive or negative reviews. For example, if an adjective appear 5 times in the top 50 of negative list and it does not appear in the top 50 of the positive list, mark it as `0` in this new dataframe (call it `top_adjectives`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e2e880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positives = pd.DataFrame(\n",
    "    [\n",
    "        [count[0] for count in nltk.FreqDist(adjectives_positive).most_common(50)],\n",
    "        [count[1] for count in nltk.FreqDist(adjectives_positive).most_common(50)]\n",
    "    ],\n",
    "    index = ['adjective','positive_count']\n",
    ").T\n",
    "\n",
    "top_negatives = pd.DataFrame(\n",
    "    [\n",
    "        [count[0] for count in nltk.FreqDist(adjectives_negative).most_common(50)],\n",
    "        [count[1] for count in nltk.FreqDist(adjectives_negative).most_common(50)]\n",
    "    ],\n",
    "    index = ['adjective','negative_count']\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c727ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjectives = top_positives.merge(top_negatives, on='adjective', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e1bb0d",
   "metadata": {},
   "source": [
    "Which adjective seems to be more overweighted (meaning that it seems to appear very often on negative reviews and not on positive ones) on negative reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8d64c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>2809</td>\n",
       "      <td>2866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bad</td>\n",
       "      <td>694</td>\n",
       "      <td>2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br</td>\n",
       "      <td>1868</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>much</td>\n",
       "      <td>1323</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>1328</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>1473</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>2575</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>real</td>\n",
       "      <td>1008</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>first</td>\n",
       "      <td>974</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>old</td>\n",
       "      <td>746</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjective  positive_count  negative_count\n",
       "0       good            2809            2866\n",
       "13       bad             694            2865\n",
       "2         br            1868            2049\n",
       "6       much            1323            1414\n",
       "5     little            1328            1176\n",
       "3       many            1473            1149\n",
       "1      great            2575            1019\n",
       "7       real            1008             888\n",
       "8      first             974             877\n",
       "11       old             746             771"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_adjectives.sort_values(by='negative_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce07bb9",
   "metadata": {},
   "source": [
    "And on the positive reviews? Do we have more than one objective that is overweighted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd3e58c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>2809</td>\n",
       "      <td>2866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>2575</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br</td>\n",
       "      <td>1868</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>1473</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best</td>\n",
       "      <td>1371</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>1328</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>much</td>\n",
       "      <td>1323</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>real</td>\n",
       "      <td>1008</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>first</td>\n",
       "      <td>974</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new</td>\n",
       "      <td>914</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adjective  positive_count  negative_count\n",
       "0      good            2809            2866\n",
       "1     great            2575            1019\n",
       "2        br            1868            2049\n",
       "3      many            1473            1149\n",
       "4      best            1371             662\n",
       "5    little            1328            1176\n",
       "6      much            1323            1414\n",
       "7      real            1008             888\n",
       "8     first             974             877\n",
       "9       new             914             678"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_adjectives.sort_values(by='positive_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2849de",
   "metadata": {},
   "source": [
    "Based on the `cleaned_tokens` object, stem all words available in our reviews and save the object in a new list of lists. Named the new object `stemmed_tokens`. Use the `SnowballStemmer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6112f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6bf2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tokens = []\n",
    "for review in cleaned_tokens:\n",
    "    stemmed_review = []\n",
    "    for token in review:\n",
    "        stemmed_token = snowball.stem(token)\n",
    "        stemmed_review.append(stemmed_token)\n",
    "    stemmed_tokens.append(stemmed_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3120d25",
   "metadata": {},
   "source": [
    "Add the percentage of retained data (number of characters retained for each review in the `cleaned_tokens` divided by the number of characters of the original review) to the `imdb_data`. Name the new column `perc_retain_stemming`. Which review loses more data with stemming? \n",
    "<br>\n",
    "<br>\n",
    "After finding it, print the review and the stemmed version of that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91abfb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_loss = []\n",
    "for index, review in enumerate(stemmed_tokens):\n",
    "    perc_loss.append(len(' '.join(review))/len(reviews[index])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0af3b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data['perc_retain_stemming'] = perc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87d554dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>perc_retain_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48927</th>\n",
       "      <td>Smallville episode Justice is the best episode...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.110272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39182</th>\n",
       "      <td>Smallville episode Justice is the best episode...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.110272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45723</th>\n",
       "      <td>What is the story what is it on the screen. At...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.390173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48697</th>\n",
       "      <td>Maybe it was the fact that I saw Spider-man th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.391213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>No offense to anyone who saw this and liked it...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.404545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>I wouldn't rent this one even on dollar rental...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30527</th>\n",
       "      <td>As so many others have written, this is a wond...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.813246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28920</th>\n",
       "      <td>Primary plot!Primary direction!Poor interpreta...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36844</th>\n",
       "      <td>OZ is the greatest show ever mad full stop.OZ ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.836257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45315</th>\n",
       "      <td>.....whoops - looks like it's gonna cost you a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.878082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "48927  Smallville episode Justice is the best episode...  positive   \n",
       "39182  Smallville episode Justice is the best episode...  positive   \n",
       "45723  What is the story what is it on the screen. At...  negative   \n",
       "48697  Maybe it was the fact that I saw Spider-man th...  negative   \n",
       "11645  No offense to anyone who saw this and liked it...  negative   \n",
       "...                                                  ...       ...   \n",
       "11926  I wouldn't rent this one even on dollar rental...  negative   \n",
       "30527  As so many others have written, this is a wond...  positive   \n",
       "28920  Primary plot!Primary direction!Poor interpreta...  negative   \n",
       "36844  OZ is the greatest show ever mad full stop.OZ ...  positive   \n",
       "45315  .....whoops - looks like it's gonna cost you a...  positive   \n",
       "\n",
       "       perc_retain_stemming  \n",
       "48927              0.110272  \n",
       "39182              0.110272  \n",
       "45723              0.390173  \n",
       "48697              0.391213  \n",
       "11645              0.404545  \n",
       "...                     ...  \n",
       "11926              0.811321  \n",
       "30527              0.813246  \n",
       "28920              0.823529  \n",
       "36844              0.836257  \n",
       "45315              0.878082  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.sort_values(by='perc_retain_stemming',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32eb48ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.loc[48927,'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d5f7c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"smallvill episod justic best episod smallvill 's favorit episod smallvill\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stemmed_tokens[48927])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17e6e1",
   "metadata": {},
   "source": [
    "What conclusion do you have after reading that review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dba9c",
   "metadata": {},
   "source": [
    "- The stemmed review retained few original characters because of the punctuation and not because of stemming. It probably may be excluded from the analysis as it contain few meaningful text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
