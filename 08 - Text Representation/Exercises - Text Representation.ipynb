{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook contains the exercise solutions for the Text Representation Section of the Natural Language Processing Course. \n",
    "<br>\n",
    "<br>\n",
    "If you have any question refer to the Lecture **'Tutorial - How to complete the exercises'** in section 2 of the course.\n",
    "<br>\n",
    "<br>\n",
    "**NOTE: Depending on your Python version and library versions, your code may be correct but it may fail the asserts in the Validation cells - if your code matches the one on the solutions, don't worry and consider your exercise correct.**\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the txt file in exercise data \n",
    "# Called positive_movie_review.txt \n",
    "# into an object called positive_review\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Tokenize the positive_review \n",
    "# file into sentences using sent_tokenize\n",
    "# and store in a review_token object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Create a one-hot vectorized version of the\n",
    "# positive review and call the object \n",
    "# vector_positive_review\n",
    "# You should have a row for each sentence\n",
    "\n",
    "# Save it as a pandas object (using the vocab as column names)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Create a count vectorize version (count of the number of words) of the \n",
    "# review_token object and store it\n",
    "# in a dataframe called \n",
    "# vector_positive_review_count\n",
    "\n",
    "# Use the vocab as column names\n",
    "\n",
    "# Only use words that appear\n",
    "# in more than 1% of the corpus\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv_count = CountVectorizer(binary=False, min_df=0.01)\n",
    "\n",
    "with open('./exercise_data/positive_movie_review.txt', encoding='utf-8') as f:\n",
    "    assert_1 = f.read()\n",
    "\n",
    "try:\n",
    "    positive_review\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object positive_review?')\n",
    "    \n",
    "try:\n",
    "    review_token\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object review_token?')\n",
    "    \n",
    "try:\n",
    "    vector_positive_review\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object vector_positive_review?')\n",
    "    \n",
    "try:\n",
    "    vector_positive_review_count\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object vector_positive_review_count?')\n",
    "\n",
    "assert_2 = sent_tokenize(assert_1)\n",
    "    \n",
    "assert(assert_1 == positive_review)\n",
    "assert(assert_2 == review_token)\n",
    "assert(pd.DataFrame(\n",
    "    cv.fit_transform(assert_2).todense(),\n",
    "    columns=cv.get_feature_names_out()\n",
    ").equals(vector_positive_review))\n",
    "assert(pd.DataFrame(\n",
    "    cv_count.fit_transform(assert_2).todense(),\n",
    "    columns=cv_count.get_feature_names_out()\n",
    ").equals(vector_positive_review_count))\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the txt file in exercise data \n",
    "# Called negative_movie_review.txt \n",
    "# into an object called negative_review\n",
    "\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Tokenize the negative_review \n",
    "# file into sentences using sent_tokenize\n",
    "# and store in a review_token_neg object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Score the TF-IDF for the word killer in the\n",
    "# first sentence of the corpora tokenized above.\n",
    "\n",
    "# Remember that you have to:\n",
    "# - count the occurences of the word in the sentence\n",
    "# - check the presence of the word in the other sentences\n",
    "# - apply the formula we have learned in the lectures\n",
    "\n",
    "# Name the object tf_idf_killer_score\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Use the TFIDF Vectorizer on the \n",
    "# review_token_neg object \n",
    "# and store the object in a sparse matrix format\n",
    "# called sparse_tf\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tftest = TfidfVectorizer()\n",
    "\n",
    "with open('./exercise_data/negative_movie_review.txt', encoding='utf-8') as f:\n",
    "    assert_1 = f.read()\n",
    "\n",
    "try:\n",
    "    negative_review\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object negative_review?')\n",
    "    \n",
    "try:\n",
    "    review_token_neg\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object review_token_neg?')\n",
    "    \n",
    "try:\n",
    "    tf_idf_killer_score\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object tf_idf_killer_score?')\n",
    "    \n",
    "try:\n",
    "    sparse_tf\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object sparse_tf?')\n",
    "\n",
    "assert_2 = sent_tokenize(assert_1)\n",
    "assert_3 = 1.792\n",
    "assert_4 = tftest.fit_transform(assert_2)\n",
    "\n",
    "assert(assert_1 == negative_review)\n",
    "assert(assert_2 == review_token_neg)\n",
    "assert(np.round(tf_idf_killer_score, 3) == assert_3)\n",
    "assert(np.allclose(assert_4.todense(),sparse_tf.todense()))\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy and load the spacy model en_core_web_md into\n",
    "# your Python environment\n",
    "\n",
    "# Save the model load into an object named nlp\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Define a function that takes two vectors and outputs the cosine similarity\n",
    "# between them. Use any method you would prefer \n",
    "    \n",
    "# call the function compute_similarity\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Extract the embeddings (using spacy) for the sentences: \n",
    "# sent1 = \"The cat sat on the mat.\"\n",
    "# sent2 = \"A feline is on the rug.\"\n",
    "\n",
    "# Save your vectors in a embed_1 and embed_2 object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Use your function compute_similarity to calculate the similarity\n",
    "# between embed_1 and embed_2 \n",
    "\n",
    "# Save the similarity in an object named sim_1 \n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Calculate the similarity of both sentences but\n",
    "# using the one-hot vectorizer approach\n",
    "\n",
    "# save the similarity in a sim_2 named object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Answer the following question: Based on the similarities using\n",
    "# one-hot vectorizer and document vectors (word2vec based), which \n",
    "# method extracts better \"meaning\" from the sentences?\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Test for function existence\n",
    "try:\n",
    "    compute_similarity\n",
    "except NameError:\n",
    "    raise NameError('Did you define the function compute_similarity?')\n",
    "\n",
    "# Test for vector existence\n",
    "try:\n",
    "    embed_1\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object embed_1?')\n",
    "\n",
    "try:\n",
    "    embed_2\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object embed_2?')\n",
    "\n",
    "# Test for similarity calculations\n",
    "try:\n",
    "    sim_1\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object sim_1?')\n",
    "\n",
    "try:\n",
    "    sim_2\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object sim_2?')\n",
    "\n",
    "# Actual values for assertions\n",
    "assert_sentences = ['The cat sat on the mat.', 'A feline is on the rug.']\n",
    "cv_assert = CountVectorizer(binary=True)\n",
    "sparse_matrix_assert = cv_assert.fit_transform(assert_sentences).todense()\n",
    "\n",
    "assert_embed_1 = nlp('The cat sat on the mat.').vector\n",
    "assert_embed_2 = nlp('A feline is on the rug.').vector\n",
    "assert_sim_1 = compute_similarity(assert_embed_1, assert_embed_2)\n",
    "assert_sim_2 = compute_similarity(sparse_matrix_assert[0].tolist()[0], sparse_matrix_assert[1].tolist()[0])\n",
    "\n",
    "# Making sure the values match the ones provided\n",
    "assert np.array_equal(embed_1, assert_embed_1)\n",
    "assert np.array_equal(embed_2, assert_embed_2)\n",
    "assert np.allclose(sim_1, assert_sim_1)\n",
    "assert np.allclose(sim_2, assert_sim_2)\n",
    "\n",
    "print('Your code is correct!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
