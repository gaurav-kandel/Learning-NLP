{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Welcome to this notebook where we embark on a fascinating exploration of the NLTK Stemming and Lemmatization functions. Our focus will be on both sentence and word tokenization. Stemming and lemmatization are powerful techniques used in natural language processing to reduce words to their base or root forms, enabling us to analyze text more effectively. Throughout this journey, we will gain insights into the inner workings of these functions and understand their importance in various NLP tasks. By the end, you will have a solid understanding of how stemming and lemmatization can enhance your text analysis capabilities.\n",
    "<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.1 - Stemming](#1.1---Stemming)\n",
    "<br>\n",
    "[1.2 - Lemmatization](#1.2---Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining the same sentence that we've seen in the first notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_definition = '''\n",
    "The European Union (EU) is a political and economic union of 27 member states that are located primarily \n",
    "in Europe. Its members have a combined area of 4,233,255.3 km2 (1,634,469.0 sq mi) and an estimated total \n",
    "population of about 447 million. The EU has developed an internal single market through a standardised system of \n",
    "laws that apply in all member states in those matters, and only those matters, where members have agreed to act as one. \n",
    "EU policies aim to ensure the free movement of people, goods, services and capital within the internal market;\n",
    "enact legislation in justice and home affairs; and maintain common policies on trade, agriculture, \n",
    "fisheries and regional development. Passport controls have been abolished for travel within the Schengen Area.\n",
    "A monetary union was established in 1999, coming into full force in 2002, and is composed of 19 EU \n",
    "member states which use the euro currency. The EU has often been described as a sui generis political entity \n",
    "(without precedent or comparison).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are really important processes of the NLP process - as we've discussed in the past, computers store strings as binary numeric objects. So words such as \"run\" and \"running\" are completely different for any system.\n",
    "<br>\n",
    "<br>\n",
    "Sometimes, this is convenient and sometimes it is not. With the rise of Neural Networks and powerful language models, some researchers argue that, in the near future there won't be a need to stem or lemmatize.\n",
    "<br>\n",
    "<br>\n",
    "Nevertheless, for some applications today it is still an important process of the NLP pipeline.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "First let's understand what Stemming is. Stemming is a more \"raw\" technique than lemmatization and consists of word \"cutting\" to the first few characters that represent a \"suffix\" of the word. This is not based on a semantic root (meaning) but on a \"written\" root called *suffix stripping*.\n",
    "\n",
    "There are different stemmers out there - the most famous are:\n",
    "- PorterStemmer;\n",
    "- SnowballStemmer;\n",
    "- LancasterStemmer;\n",
    "\n",
    "They are sorted by order of \"aggressiveness\" - the main problems occuring from stemming are **under-stemming** or **over-stemming**.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk` has some nice implementations of the three stemmers named above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example between the stemmers with different words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controvers\n",
      "controversi\n",
      "controversi\n"
     ]
    }
   ],
   "source": [
    "word = 'controversial'\n",
    "\n",
    "print(lancaster.stem(word))\n",
    "print(snowball.stem(word))\n",
    "print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controversy\n",
      "controversi\n",
      "controversi\n"
     ]
    }
   ],
   "source": [
    "word = 'controversy'\n",
    "\n",
    "print(lancaster.stem(word))\n",
    "print(snowball.stem(word))\n",
    "print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraordinair\n",
      "extraordinair\n",
      "extraordinair\n"
     ]
    }
   ],
   "source": [
    "word = 'extraordinaire'\n",
    "\n",
    "print(lancaster.stem(word))\n",
    "print(snowball.stem(word))\n",
    "print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraordin\n",
      "extraordinari\n",
      "extraordinari\n"
     ]
    }
   ],
   "source": [
    "word = 'extraordinary'\n",
    "\n",
    "print(lancaster.stem(word))\n",
    "print(snowball.stem(word))\n",
    "print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancaster Stemmer usually over-stemms the words. There isn't a big difference between Snowball and Porter stemmer (they sometimes differ in certain words). A huge difference is that `nltk` implementation of Snowball supports multi-language while Porter Stemmer does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's stem an entire sentence using Snowball:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look, we are compounding learnings now, great! Applying a word stemmer:\n",
    "tokenized_eu_definition = nltk.tokenize.word_tokenize(eu_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's not apply our snowball stemmer to every word on the eu_definition\n",
    "stemmed_eu_definition = [snowball.stem(word) for word in tokenized_eu_definition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our text gets a bit.. funky:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the european union ( eu ) is a polit and econom union of 27 member state that are locat primarili in europ . it member have a combin area of 4,233,255.3 km2 ( 1,634,469.0 sq mi ) and an estim total popul of about 447 million . the eu has develop an intern singl market through a standardis system of law that appli in all member state in those matter , and onli those matter , where member have agre to act as one . eu polici aim to ensur the free movement of peopl , good , servic and capit within the intern market ; enact legisl in justic and home affair ; and maintain common polici on trade , agricultur , fisheri and region develop . passport control have been abolish for travel within the schengen area . a monetari union was establish in 1999 , come into full forc in 2002 , and is compos of 19 eu member state which use the euro currenc . the eu has often been describ as a sui generi polit entiti ( without preced or comparison ) .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(stemmed_eu_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our text is almost unreadable for a human, for a computer it may be better to understand it in this way (particularly for simpler applications) - imagine you want to classify some text as \"Positive\" (a common case in sentiment analysis) then words such as `positive`, `positivity` or `positiviness` might have some impact in that classification and you may want to consider them the same type of \"expression\".\n",
    "<br>\n",
    "<br>\n",
    "Us, as humans, can understand that these words are derived from the suffix \"positiv\", but a computer does not as it only sees 1's and 0's. Hence, stemming explicitly tells the computer that it should treat positive, positivity or positiviness as the same *word*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has some advantages and some disadvantages.\n",
    "<br>\n",
    "<br>\n",
    "Here are some advantages of stemming:\n",
    "- Word generalization;\n",
    "- Increased Data Consistency;\n",
    "- Reduced Vocabulary Size;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the downside, stemming has the following setbacks:\n",
    "- Is simplistic and may produce errors;\n",
    "- Cause loss of information;\n",
    "- With the rise of better language models, it may become obsolete;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the amount of information retained from the original sentence (in terms of original characters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_number_characters = len(''.join(stemmed_eu_definition))\n",
    "non_stemmed_number_characters = len(''.join(tokenized_eu_definition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After stemming, we retain ~90% of the original information of the description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956109134045077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_number_characters/non_stemmed_number_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information loss is about **10%** (1 minus the original information retained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of obtaining the **root** of the word. It's different from Stemming as it is related to the morphological characteristic of the word.\n",
    "<br>\n",
    "<br>\n",
    "Another important part is that it is related to a `POS(Part-of-Speech)` of the word. We'll understand what a POS really is in subsequent lectures.\n",
    "<br>\n",
    "Let's go for **lemmatization**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet is a lexical database for the English Language that estabilish semantic relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creating'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('creating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball.stem('creating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems weird - while our stemmer is able to create a \"root\" of the word create - **lemmatize seems to fail on that simple task.**\n",
    "<br>\n",
    "<br>\n",
    "That's because the lemmatizer needs to know what's the class (or the part-of-speech tag) of the word. We need to give that tag to the lemmatizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('creating', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the pos classes we can pass to lemmatize:\n",
    "- Adjectives: `'a'`\n",
    "- Noun: `'n'`\n",
    "- Verb: `'v'`\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also `'r'` which is adverb  - we have to map the word in the sentence to have a correct lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example on obtaining the *lemma* of an adjective - this is where the lemmatization really shines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"worse\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"better\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example with plural nouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"cats\", pos='n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Here we are passing the POS tag on our own - is there a way to obtain this type of POS class automatically? \n",
    "<br>\n",
    "Yes, there is! That's what we are going to learn in the next notebook!\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
