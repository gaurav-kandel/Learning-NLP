{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook contains the exercises for the Natural Language Toolkit Section of the Natural Language Processing Course. \n",
    "<br>\n",
    "<br>\n",
    "You can run your notebook on each cell that has a heading that starts with \"Exercise\" and validate your solution on each cell that has an heading that starts with \"Validation\".\n",
    "<br>\n",
    "<br>\n",
    "Don't forget that you code must in the bits with ```### YOUR CODE HERE``` and check if you create every object that the function expects!\n",
    "<br>\n",
    "There's an accompanying notebook that contains the solutions, if you need some help!\n",
    "<br>\n",
    "If you have any question refer to the Lecture **'Tutorial - How to complete the exercises'** in section 2 of the course.\n",
    "<br>\n",
    "<br>\n",
    "**NOTE: Depending on your Python version and library versions, your code may be correct but it may fail the asserts in the Validation cells - if your code matches the one on the solutions, don't worry and consider your exercise correct.**\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_the_wind_quote = '''\n",
    "It was far too much for me to deal with at the moment, weary, wounded,\n",
    "and still somewhat the worse for drink. Instead I quickly cleaned the shallow cut as best I could using my washbasin. I would have put some stitches\n",
    "in it myself, but I couldn't get a good angle. It started bleeding again, and I\n",
    "cut off the cleaner pieces of my ruined shirt to fashion a makeshift bandage.\n",
    "Blood. The men who tried to kill me still had the dowsing compass, and\n",
    "I'd undoubtedly left some of my blood on his knife. Blood would be vastly\n",
    "more effective in a dowsing compass than a simple hair; that meant that even\n",
    "if they didn't already know where I lived, they might be able to find me despite the precautions I'd taken.\n",
    "I moved around my room quickly, stuffing everything of value into my\n",
    "travelsack, as I didn't know when it would be safe to return. Under a stack\n",
    "of papers I found a small folding knife I'd forgotten about, after I'd won it\n",
    "off Sim playing corners. It would be worth next to nothing in a fight, but\n",
    "that was better than nothing at all.\n",
    "Then I grabbed my lute and cloak and snuck downstairs into the kitchen,\n",
    "where I was lucky enough to find an empty Velegen wine pot with a wide\n",
    "mouth. It was a minor piece of luck, but I was glad for whatever I could get\n",
    "at this point.\n",
    "'''\n",
    "\n",
    "# Use NLTK Sent Tokenize to tokenize\n",
    "# the name_of_the_wind_quote object\n",
    "# and store it in an object called\n",
    "# tokenized_name_of_the_wind\n",
    "\n",
    "# Hint: Don't forget to install\n",
    "# and load the nltk library!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Use word tokenize to tokenize the first\n",
    "# sentence of the object tokenized_name_of_the_wind\n",
    "# Store the resulting tokenized word version\n",
    "# in an object called word_token\n",
    "\n",
    "word_token = nltk.tokenize.word_tokenize(\n",
    "    tokenized_name_of_the_wind[0]\n",
    ")\n",
    "\n",
    "# Extract the most common word per sentence\n",
    "# in the name_of_the_wind_quote\n",
    "\n",
    "# Your returning object should contain\n",
    "# a dictionary with the index of the sentence\n",
    "# as key and the most common word as value\n",
    "\n",
    "# Give the name most_common_word\n",
    "# to the dictionary\n",
    "\n",
    "# Hint: You can use enumerate to loop through\n",
    "# each sentence and obtain the sentence and the index!\n",
    "\n",
    "# Hint 2: Freq Dist can help you to get the most common\n",
    "# word! Don't forget that freq dist returns a tuple and\n",
    "# we only want the word!\n",
    "\n",
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tokenized_name_of_the_wind\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object tokenized_name_of_the_wind?')\n",
    "    \n",
    "try:\n",
    "    word_token\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object word_token?')\n",
    "    \n",
    "try:\n",
    "    most_common_word\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object most_common_word?')\n",
    "\n",
    "assert_1 = ['\\nIt was far too much for me to deal with at the moment, weary, wounded,\\nand still somewhat the worse for drink.',\n",
    " 'Instead I quickly cleaned the shallow cut as best I could using my washbasin.',\n",
    " \"I would have put some stitches\\nin it myself, but I couldn't get a good angle.\",\n",
    " 'It started bleeding again, and I\\ncut off the cleaner pieces of my ruined shirt to fashion a makeshift bandage.',\n",
    " 'Blood.',\n",
    " \"The men who tried to kill me still had the dowsing compass, and\\nI'd undoubtedly left some of my blood on his knife.\",\n",
    " \"Blood would be vastly\\nmore effective in a dowsing compass than a simple hair; that meant that even\\nif they didn't already know where I lived, they might be able to find me despite the precautions I'd taken.\",\n",
    " \"I moved around my room quickly, stuffing everything of value into my\\ntravelsack, as I didn't know when it would be safe to return.\",\n",
    " \"Under a stack\\nof papers I found a small folding knife I'd forgotten about, after I'd won it\\noff Sim playing corners.\",\n",
    " 'It would be worth next to nothing in a fight, but\\nthat was better than nothing at all.',\n",
    " 'Then I grabbed my lute and cloak and snuck downstairs into the kitchen,\\nwhere I was lucky enough to find an empty Velegen wine pot with a wide\\nmouth.',\n",
    " 'It was a minor piece of luck, but I was glad for whatever I could get\\nat this point.']\n",
    "\n",
    "assert_2 = ['It',\n",
    " 'was',\n",
    " 'far',\n",
    " 'too',\n",
    " 'much',\n",
    " 'for',\n",
    " 'me',\n",
    " 'to',\n",
    " 'deal',\n",
    " 'with',\n",
    " 'at',\n",
    " 'the',\n",
    " 'moment',\n",
    " ',',\n",
    " 'weary',\n",
    " ',',\n",
    " 'wounded',\n",
    " ',',\n",
    " 'and',\n",
    " 'still',\n",
    " 'somewhat',\n",
    " 'the',\n",
    " 'worse',\n",
    " 'for',\n",
    " 'drink',\n",
    " '.']\n",
    "\n",
    "assert_3 = {0: ',',\n",
    " 1: 'I',\n",
    " 2: 'I',\n",
    " 3: 'It',\n",
    " 4: 'Blood',\n",
    " 5: 'The',\n",
    " 6: 'be',\n",
    " 7: 'I',\n",
    " 8: 'I',\n",
    " 9: 'nothing',\n",
    " 10: 'I',\n",
    " 11: 'was'}\n",
    "\n",
    "assert(tokenized_name_of_the_wind == assert_1)\n",
    "assert(word_token == assert_2)\n",
    "assert(most_common_word == assert_3)\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use snowball stemmer on the tokenized word\n",
    "# version of the full name_of_the_wind_quote\n",
    "\n",
    "# Don't forget that you have to apply tokenization\n",
    "# first!\n",
    "\n",
    "# Store the stemmed sentence in list format\n",
    "# in an object called list_stemming\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Join the list list_stemming by a ' '\n",
    "# and store it in an object stemmed_sent\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Calculate the % of letters retained\n",
    "# from the original sentence \n",
    "# in the stemmed_sent\n",
    "\n",
    "# Name the object stem_retain\n",
    "\n",
    "# Round the resulting number \n",
    "# to 2 decimal places\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    list_stemming\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object list_stemming?')\n",
    "    \n",
    "try:\n",
    "    stemmed_sent\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object stemmed_sent?')\n",
    "    \n",
    "try:\n",
    "    stem_retain\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object stem_retain?')\n",
    "\n",
    "assert_4 = ['it','was','far','too','much','for','me','to','deal','with','at','the','moment',',','weari',',','wound',',','and',\n",
    " 'still','somewhat','the','wors','for','drink','.','instead','i','quick','clean','the','shallow','cut','as','best','i','could','use',\n",
    " 'my','washbasin','.','i','would','have','put','some','stitch','in','it','myself',',','but','i','could',\"n't\",\n",
    " 'get','a','good','angl','.','it','start','bleed','again',',','and','i','cut','off','the','cleaner','piec','of',\n",
    " 'my','ruin','shirt','to','fashion','a','makeshift','bandag','.','blood','.','the','men','who','tri','to','kill','me','still',\n",
    " 'had','the','dows','compass',',','and','i',\"'d\",'undoubt','left','some','of','my','blood','on','his','knife','.','blood','would',\n",
    " 'be','vast','more','effect','in','a','dows','compass','than','a','simpl','hair',';','that','meant','that','even','if','they',\n",
    " 'did',\"n't\",'alreadi','know','where','i','live',',','they','might','be','abl','to','find','me','despit','the','precaut','i',\"'d\",'taken',\n",
    " '.','i','move','around','my','room','quick',',','stuf','everyth','of','valu','into','my','travelsack',',','as','i','did',\"n't\",\n",
    " 'know','when','it','would','be','safe','to','return','.','under','a','stack','of','paper','i','found','a','small','fold','knife',\n",
    " 'i',\"'d\",'forgotten','about',',','after','i',\"'d\",'won','it','off','sim','play','corner','.','it','would',\n",
    " 'be','worth','next','to','noth','in','a','fight',',','but','that','was','better','than','noth','at','all','.','then','i',\n",
    " 'grab','my','lute','and','cloak','and','snuck','downstair','into','the','kitchen',',','where','i','was','lucki','enough',\n",
    " 'to','find','an','empti','velegen','wine','pot','with','a','wide','mouth','.','it','was',\n",
    " 'a','minor','piec','of','luck',',','but','i','was','glad','for','whatev','i','could','get','at','this','point','.']\n",
    "\n",
    "assert_5 = \"it was far too much for me to deal with at the moment , weari , wound , and still somewhat the wors for drink . instead i quick clean the shallow cut as best i could use my washbasin . i would have put some stitch in it myself , but i could n't get a good angl . it start bleed again , and i cut off the cleaner piec of my ruin shirt to fashion a makeshift bandag . blood . the men who tri to kill me still had the dows compass , and i 'd undoubt left some of my blood on his knife . blood would be vast more effect in a dows compass than a simpl hair ; that meant that even if they did n't alreadi know where i live , they might be abl to find me despit the precaut i 'd taken . i move around my room quick , stuf everyth of valu into my travelsack , as i did n't know when it would be safe to return . under a stack of paper i found a small fold knife i 'd forgotten about , after i 'd won it off sim play corner . it would be worth next to noth in a fight , but that was better than noth at all . then i grab my lute and cloak and snuck downstair into the kitchen , where i was lucki enough to find an empti velegen wine pot with a wide mouth . it was a minor piec of luck , but i was glad for whatev i could get at this point .\"\n",
    "\n",
    "assert(list_stemming == assert_4)\n",
    "assert(stemmed_sent == assert_5)\n",
    "assert(stem_retain == 0.96)\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Unigram Tagger on the Brown Corpus\n",
    "# News Category - use all the tagged data\n",
    "# from the brown corpus\n",
    "\n",
    "# Store your model in an object \n",
    "# named unigram_tag\n",
    "\n",
    "# Hint: Don't forget to import the brown\n",
    "# corpus! \n",
    "# Hint 2: Don't forget to import the UnigramTagger!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Apply your unigram tag to the name_of_the_wind_quote\n",
    "# don't forget that you need to tokenize the sentence\n",
    "# to apply the tagger!\n",
    "\n",
    "# Also lower your sentence passed to the tagger\n",
    "# Call your POS tagged tag name_of_the_wind_tag\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Count the number of NN's (tag = NN)\n",
    "# in the sentence \n",
    "\n",
    "# Store the number of NN's in an object\n",
    "# named NN_count\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "brown_tagged_sents_reviews = brown.tagged_sents(categories='news')\n",
    "unigram_tag = UnigramTagger(brown_tagged_sents_reviews)\n",
    "\n",
    "try:\n",
    "    name_of_the_wind_tag\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object name_of_the_wind_tag?')\n",
    "       \n",
    "try:\n",
    "    NN_count\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object NN_count?')\n",
    "    \n",
    "\n",
    "assert(name_of_the_wind_tag == unigram_tag.tag(\n",
    "    nltk.tokenize.word_tokenize(name_of_the_wind_quote.lower())\n",
    "))\n",
    "assert(NN_count == 16)\n",
    "\n",
    "print('Your code is correct!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
