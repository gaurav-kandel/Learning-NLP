{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook contains the exercise solutions for the Text Classification Section of the Natural Language Processing Course. \n",
    "<br>\n",
    "<br>\n",
    "If you have any question refer to the Lecture **'Tutorial - How to complete the exercises'** in section 2 of the course.\n",
    "<br>\n",
    "<br>\n",
    "**NOTE: Depending on your Python version and library versions, your code may be correct but it may fail the asserts in the Validation cells - if your code matches the one on the solutions, don't worry and consider your exercise correct.**\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Obtaining and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the spam.csv file using pandas\n",
    "# Store the file in an object named \n",
    "# spam_file\n",
    "import pandas as pd\n",
    "spam_file = pd.read_csv('./data/spam.csv')\n",
    "\n",
    "    \n",
    "# Lower case the text column  in the spam_file\n",
    "# data frame\n",
    "spam_file['text'] = spam_file.text.str.lower()\n",
    "\n",
    "# Remove all punctuation from the text column\n",
    "# in the spam_file data frame\n",
    "import string\n",
    "spam_file['text'] = spam_file['text'].apply(lambda x: \n",
    "    x.translate(\n",
    "        str.maketrans('', '', string.punctuation)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Transform the label column into 1 and 0 by stating\n",
    "# that the value should be 1 when label = 'spam' and 0\n",
    "# otherwise\n",
    "import numpy as np\n",
    "spam_file['label'] = np.where(\n",
    "    spam_file['label']=='spam',1,0\n",
    ")\n",
    "\n",
    "# Split the data into train and test, you can use\n",
    "# using 80% of the data to train the algorithm\n",
    "\n",
    "# Use the text column as X (features) and the label\n",
    "# as y (target). \n",
    "\n",
    "# Name your object X_train, X_test, y_train, y_test\n",
    "# respectively\n",
    "\n",
    "# Use Random State = 20\n",
    "\n",
    "# Hint: use sklearn train_test_split!\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(spam_file.text, spam_file.label, test_size=0.2, random_state=20)\n",
    ")\n",
    "\n",
    "# Use tf-idf transformation on the X_train to obtain features\n",
    "# for our algorithm\n",
    "\n",
    "# Use min_df = 0.02 as argument for the tf-idf\n",
    "\n",
    "# Rewrite the X_Train object into a dense (2D) format\n",
    "\n",
    "# Name the object tfv\n",
    "\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer\n",
    ")\n",
    "\n",
    "tfv = TfidfVectorizer(min_df = 0.02)\n",
    "X_train = tfv.fit_transform(X_train).todense()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer\n",
    ")\n",
    "import string\n",
    "\n",
    "cv_val = TfidfVectorizer(min_df = 0.02)\n",
    "assert_1 = pd.read_csv('./data/spam.csv')\n",
    "\n",
    "try:\n",
    "    spam_file\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object spam_file?')\n",
    "    \n",
    "try:\n",
    "    X_train\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object X_train?')\n",
    "    \n",
    "try:\n",
    "    X_test\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object X_test?')\n",
    "    \n",
    "try:\n",
    "    y_train\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object y_train?')\n",
    "    \n",
    "try:\n",
    "    y_test\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object y_test?')\n",
    "\n",
    "assert_1['text'] = assert_1.text.str.lower()\n",
    "assert_1['text'] = assert_1['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "assert_1['label'] = np.where(\n",
    "    assert_1['label']=='spam',1,0\n",
    ")\n",
    "\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = (\n",
    "    train_test_split(assert_1.text, assert_1.label, test_size=0.2, random_state=20)\n",
    ")\n",
    "\n",
    "X_train_val = cv_val.fit_transform(X_train_val).todense()  \n",
    "\n",
    "assert(assert_1).equals(spam_file)\n",
    "assert(pd.DataFrame(X_train)).equals(pd.DataFrame(X_train_val))\n",
    "assert(X_test).equals(X_test_val)\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic Regression using X_train to predict\n",
    "# y_train\n",
    "\n",
    "# Use random state 1234\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lm = LogisticRegression(random_state=1234)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Using the trained logistic regression, predict\n",
    "# the class of a sentence being spam on the\n",
    "# test set \n",
    "\n",
    "# Remember to use transform to obtain the stored \n",
    "# tf-idf we've set up above!\n",
    "\n",
    "# Save the predictions in a y_pred object\n",
    "# Your predictions should have format 1/0 and not probability\n",
    "\n",
    "y_pred = lm.predict(tfv.transform(X_test).todense())\n",
    "\n",
    "# Compare the labels you have obtained from your model with\n",
    "# the real labels and compute the accuracy\n",
    "\n",
    "# Hint: You can compute accuracy using accuracy_score from sklearn\n",
    "# or manually!\n",
    "\n",
    "# Store the accuracy in a acc named object\n",
    "\n",
    "acc = sum(y_pred==y_test)/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "lm_val = LogisticRegression(random_state=1234)\n",
    "lm_val.fit(X_train_val, y_train_val)\n",
    "\n",
    "try:\n",
    "    y_pred\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object y_pred?')\n",
    "    \n",
    "try:\n",
    "    acc\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object acc?')\n",
    "\n",
    "lm_val = LogisticRegression(random_state=1234)\n",
    "lm_val.fit(X_train_val, y_train_val)\n",
    "\n",
    "y_pred_val = lm_val.predict(cv.transform(X_test).todense())\n",
    "\n",
    "acc_val = sum(y_pred_val==y_test_val)/len(y_pred_val)\n",
    "\n",
    "assert(pd.DataFrame(y_pred)).equals(pd.DataFrame(y_pred_val))\n",
    "assert(str(round(acc, 4)) == '0.9596')\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Predicting New Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a sentence named 'FREE entry, CLICK HERE to receive yr free entry wr waiting fr you and we ned u in our free amzing website were yll get free stuff' \n",
    "# in an object named sent_1\n",
    "\n",
    "sent_1 = 'FREE entry, CLICK HERE to receive yr free entry wr waiting fr you and we ned u in our free amzing website were yll get free stuff'\n",
    "\n",
    "# Pass the sentence 1 through the pipeline we've created\n",
    "# Don't forget to lower case the text and remove punctuation \n",
    "# to match the pipeline we've used above!\n",
    "\n",
    "# Always rewrite the sent_1 object\n",
    "sent_1 = sent_1.lower()\n",
    "sent_1 =  sent_1.translate(\n",
    "        str.maketrans('', '', string.punctuation)\n",
    ")\n",
    "\n",
    "# Transform sent_1 into tf-idf format using\n",
    "# our trained tfidf\n",
    "\n",
    "# name the object sent_1_tf\n",
    "sent_1_tf = tfv.transform([sent_1])\n",
    "\n",
    "# Predict the probability of our sentence\n",
    "# being spam using the logistic regression\n",
    "# we've trained\n",
    "\n",
    "# name it probability_spam\n",
    "probability_spam = lm_val.predict_proba(sent_1_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sent_1\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object sent_1?')\n",
    "    \n",
    "try:\n",
    "    probability_spam\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object probability_spam?')\n",
    "\n",
    "sent_1_val = (\n",
    "    'FREE entry, CLICK HERE to receive yr free entry wr waiting fr you and we ned u in our free amzing website were yll get free stuff'\n",
    ").lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "sent_1_tf_val = tfv.transform([sent_1_val])\n",
    "\n",
    "probability_spam_val = lm_val.predict_proba(sent_1_tf)\n",
    "\n",
    "assert(sent_1_val == sent_1)\n",
    "assert(np.allclose(probability_spam,probability_spam_val))\n",
    "\n",
    "print('Your code is correct!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPCourse",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
