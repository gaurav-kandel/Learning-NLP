{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook contains the exercises for the CBOW Section of the Natural Language Processing Course. \n",
    "<br>\n",
    "<br>\n",
    "You can run your notebook on each cell that has a heading that starts with \"Exercise\" and validate your solution on each cell that has an heading that starts with \"Validation\".\n",
    "<br>\n",
    "<br>\n",
    "Don't forget that you code must in the bits with ```### YOUR CODE HERE``` and check if you create every object that the function expects!\n",
    "<br>\n",
    "There's an accompanying notebook that contains the solutions, if you need some help!\n",
    "<br>\n",
    "If you have any question refer to the Lecture **'Tutorial - How to complete the exercises'** in section 2 of the course.\n",
    "<br>\n",
    "<br>\n",
    "**NOTE: Depending on your Python version and library versions, your code may be correct but it may fail the asserts in the Validation cells - if your code matches the one on the solutions, don't worry and consider your exercise correct.**\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the txt file stored in the exercise data folder\n",
    "# into a file called cbow_train \n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Tokenize your Text into Words (using nltk's default tokenizer)\n",
    "# Don't remove punctuation or stop words\n",
    "# Save the tokenized object in a \n",
    "# token_train named object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Build the vocab in a list format\n",
    "# Sort the vocab and store it in an\n",
    "# object named vocab\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Build the binary word representation\n",
    "# for each word in the vocab\n",
    "\n",
    "# named the numpy array object\n",
    "# vocab_arrays\n",
    "# Hint: remember the np.identity function!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Build a dictionary with the vocab arrays\n",
    "# as values and the word as dict\n",
    "\n",
    "# Name the object vocab_dict\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "with open('./exercise_data/cbow_file.txt', encoding='utf-8') as cbow_f:\n",
    "    assert_1 = cbow_f.read()\n",
    "\n",
    "try:\n",
    "    cbow_train\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object cbow_train?')\n",
    "    \n",
    "try:\n",
    "    vocab\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object vocab?')\n",
    "    \n",
    "try:\n",
    "    token_train\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object token_train?')\n",
    "    \n",
    "try:\n",
    "    vocab_arrays\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object vocab_arrays?')\n",
    "    \n",
    "try:\n",
    "    vocab_dict\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object vocab_dict?')\n",
    "    \n",
    "\n",
    "\n",
    "assert_2 = word_tokenize(assert_1)\n",
    "\n",
    "assert_3 = list(set(assert_2))\n",
    "assert_3.sort()\n",
    "\n",
    "assert_4 = np.identity(len(assert_3))\n",
    "\n",
    "assert_5 = {}\n",
    "for i, word in enumerate(assert_3):\n",
    "    assert_5[word] = assert_4[i]\n",
    "\n",
    "\n",
    "assert(assert_1 == cbow_train)\n",
    "assert(assert_2 == token_train)\n",
    "assert(assert_3 == vocab)\n",
    "assert(np.array_equal(assert_4, vocab_arrays))\n",
    "assert(len(assert_5) == len(vocab_dict))\n",
    "assert(list(assert_5.keys())[0] == list(vocab_dict.keys())[0])\n",
    "assert(np.array_equal(list(assert_5.values())[0],list(vocab_dict.values())[0]))\n",
    "\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN THE CODE BELOW BEFORE EXERCISE_2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip files\n",
    "with zipfile.ZipFile('./exercise_data/features.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./exercise_data/')\n",
    "with zipfile.ZipFile('./exercise_data/target.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./exercise_data/')\n",
    "\n",
    "# The X and y arrays with target and features\n",
    "# are already loaded for you in the environment\n",
    "import pickle\n",
    "with open('./exercise_data/features.pkl','rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('./exercise_data/target.pkl','rb') as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "# Run This code before doing exercises\n",
    "SEED = 123456\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "set_seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "292/292 [==============================] - 13s 29ms/step - loss: 7.0362 - accuracy: 0.0735 - val_loss: 7.0004 - val_accuracy: 0.0674\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 8s 26ms/step - loss: 6.1572 - accuracy: 0.0759 - val_loss: 7.1403 - val_accuracy: 0.0674\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 8s 26ms/step - loss: 6.0571 - accuracy: 0.0759 - val_loss: 7.2278 - val_accuracy: 0.0674\n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 7s 25ms/step - loss: 6.0028 - accuracy: 0.0759 - val_loss: 7.2846 - val_accuracy: 0.0674\n",
      "Epoch 5/10\n",
      "292/292 [==============================] - 7s 23ms/step - loss: 5.9592 - accuracy: 0.0802 - val_loss: 7.3593 - val_accuracy: 0.0674\n",
      "Epoch 6/10\n",
      "292/292 [==============================] - 7s 23ms/step - loss: 5.9173 - accuracy: 0.0834 - val_loss: 7.3745 - val_accuracy: 0.0765\n",
      "Epoch 7/10\n",
      "292/292 [==============================] - 7s 24ms/step - loss: 5.8695 - accuracy: 0.0963 - val_loss: 7.4692 - val_accuracy: 0.0863\n",
      "Epoch 8/10\n",
      "292/292 [==============================] - 7s 23ms/step - loss: 5.8125 - accuracy: 0.1059 - val_loss: 7.4949 - val_accuracy: 0.0893\n",
      "Epoch 9/10\n",
      "292/292 [==============================] - 7s 23ms/step - loss: 5.7479 - accuracy: 0.1177 - val_loss: 7.5226 - val_accuracy: 0.0966\n",
      "Epoch 10/10\n",
      "292/292 [==============================] - 7s 23ms/step - loss: 5.6790 - accuracy: 0.1304 - val_loss: 7.5779 - val_accuracy: 0.0990\n"
     ]
    }
   ],
   "source": [
    "# Build a CBOW neural Network \n",
    "# with 50 nodes in the hidden layer\n",
    "# Compile your model after adding\n",
    "# the layers\n",
    "\n",
    "# Name you model nn_model\n",
    "\n",
    "# Use 2834 neurons as vocab_size (features)\n",
    "# The hidden layer should have activation relu \n",
    "# the output layer should have activation softmax\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Fit your model on X and y for 10 epochs, use 15% \n",
    "# of your data as internal validation\n",
    "# split \n",
    "# X and y are obtained by running the cell\n",
    "# above this code\n",
    "\n",
    "# Save the fit object in a history_nn\n",
    "# object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Obtain the evolution of the validation accuracy\n",
    "# of your model from the history_nn object\n",
    "# store the resulting list in a \n",
    "# val_accuracy object\n",
    "\n",
    "# hint: you can access the validation accuracy of the network\n",
    "# by obtaining using history_nn.history['val_accuracy']\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Obtain the embeddings generated from the first to the second layer\n",
    "# of the neural network and store them in a \n",
    "# embeddings_words object\n",
    "\n",
    "# Hint: remember the get_weights method!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Obtain the embedding for the word luck\n",
    "# in the word embeddings\n",
    "# Hint: Check the index of the word in the vocab\n",
    "# object you have created in the past exercise!\n",
    "\n",
    "# Store the returning embedding in a luck_embedding\n",
    "# named object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# NOTE: There may be a chance that the asserts below don't match because of keras\n",
    "# version changes or small differences in the training of the neural network. If your\n",
    "# code matches the one on the solutions, consider it correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation - Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "assert_1 = 'Model: \"sequential\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n dense (Dense)               (None, 50)                141750    \\n                                                                 \\n dense_1 (Dense)             (None, 2834)              144534    \\n                                                                 \\n=================================================================\\nTotal params: 286284 (1.09 MB)\\nTrainable params: 286284 (1.09 MB)\\nNon-trainable params: 0 (0.00 Byte)\\n_________________________________________________________________'\n",
    "\n",
    "try:\n",
    "    nn_model\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object nn_model?')\n",
    "    \n",
    "try:\n",
    "    val_accuracy\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object val_accuracy?')\n",
    "    \n",
    "try:\n",
    "    embeddings_words\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object embeddings_words?')\n",
    "\n",
    "try:\n",
    "    luck_embedding\n",
    "except NameError:\n",
    "    raise NameError('Did you create the object luck_embedding?')\n",
    "    \n",
    "model_summary_user = []\n",
    "nn_model.summary(print_fn=lambda x: model_summary_user.append(x))\n",
    "short_model_summary = \"\\n\".join(model_summary_user)\n",
    "\n",
    "assert_2 = [0.06743621081113815,\n",
    " 0.06743621081113815,\n",
    " 0.06743621081113815,\n",
    " 0.06743621081113815,\n",
    " 0.06743621081113815,\n",
    " 0.07654920965433121,\n",
    " 0.08626974374055862,\n",
    " 0.08930741250514984,\n",
    " 0.0965978130698204,\n",
    " 0.099027946591377263]\n",
    "\n",
    "with open('./exercise_data/embeddings_val.pickle','rb') as f:\n",
    "     assert_3 = pickle.load(f)\n",
    "\n",
    "\n",
    "assert_4 = [0.08911997, 0.11617187, 0.07450133, 0.16907178, 0.18803614,\n",
    "       0.12058551, 0.05050112, 0.17586885, 0.11665037, 0.16211702,\n",
    "       0.13257873, 0.14722975, 0.16093013, 0.04666641, 0.10453457,\n",
    "       0.12503827, 0.14505675, 0.02664091, 0.03504416, 0.06340603,\n",
    "       0.11959476, 0.22390895, 0.13273549, 0.06868254, 0.1433434 ,\n",
    "       0.20631374, 0.17138377, 0.09052949, 0.04808746, 0.02552352,\n",
    "       0.12730601, 0.14560094, 0.05122316, 0.19417776, 0.15348634,\n",
    "       0.15171646, 0.07905831, 0.15822853, 0.16905384, 0.05087509,\n",
    "       0.07655411, 0.12483661, 0.09708362, 0.13148096, 0.06821381,\n",
    "       0.13283676, 0.10804287, 0.10719838, 0.11915205, 0.12653516]\n",
    "\n",
    "assert(assert_1 == short_model_summary)\n",
    "assert(assert_2 == val_accuracy)\n",
    "assert(np.allclose(assert_3,embeddings_words))\n",
    "assert(np.allclose(assert_4,luck_embedding))\n",
    "print('Your code is correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word2vec model from gensim\n",
    "# use the word2vec-google-news-300 model\n",
    "\n",
    "# save the model in a w2v named object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Store the embedding for the word portugal \n",
    "# on an object named portugal\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Store the embedding for the word spain\n",
    "# on an object named spain\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Compute the cosine similarity\n",
    "# between the two embeddings (portugal and spain)\n",
    "\n",
    "# If you use the cosine_similarity function from sklearn\n",
    "# store only the value related to the similarity of the vectors (and not\n",
    "# the entire similarity matrix)\n",
    "\n",
    "# save it in a \"similarity\" named object\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Answer (just write the answer below): Would you say \n",
    "# that the two words are similar and convey similar concepts\n",
    "# based on the similarity? \n",
    "\n",
    "### YOUR ANSWER HERE (keep the hashtags so that the answer is compiled as a comment)\n",
    "\n",
    "# Compute the similarity using the similarity function\n",
    "# from the w2v model between the words 'jeep' and 'apple'\n",
    "\n",
    "# Store the result in an object named sim_1\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Compute the similarity using the similarity function\n",
    "# from the w2v model between the words 'jeep' and 'banana'\n",
    "\n",
    "# Store the result in an object named sim_2\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# Answer (just write the answer below): \n",
    "# Why does it makes sense that apple and jeep have a higher\n",
    "# similarity than banana and jeep?\n",
    "\n",
    "### YOUR ANSWER HERE (keep the hashtags so that the answer is compiled as a comment)\n",
    "\n",
    "# Calculate the following analogy using the `most_similar` function\n",
    "# from gensim objects\n",
    "\n",
    "# sega + nintendo - sonic\n",
    "\n",
    "# Save the result in an object named analogy\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your code is correct!\n"
     ]
    }
   ],
   "source": [
    "# Assert that the w2v model was created and has expected features\n",
    "assert 'w2v' in globals(), \"Did you create the object w2v?\"\n",
    "\n",
    "assert 'portugal' in globals(), \"Did you create the object portugal?\"\n",
    "assert 'spain' in globals(), \"Did you create the object spain?\"\n",
    "assert 'similarity' in globals(), \"Did you create the object similarity?\"\n",
    "\n",
    "assert 'sim_1' in globals(), \"Did you create the object sim_1?\"\n",
    "assert 'sim_2' in globals(), \"Did you create the object sim_2?\"\n",
    "\n",
    "assert 'analogy' in globals(), \"Did you create the object analogy?\"\n",
    "\n",
    "assert_portugal = np.array(w2v['portugal'])\n",
    "assert_spain = np.array(w2v['spain'])\n",
    "assert_similarity = cosine_similarity([assert_portugal, assert_spain])[0,1]\n",
    "\n",
    "assert np.allclose(assert_portugal, portugal), \"Is your portugal embedding correct?\"\n",
    "assert np.allclose(assert_spain, spain), \"Is your spain embedding correct?\"\n",
    "assert np.isclose(assert_similarity, similarity, rtol=1e-05), \"Is your similarity value correct?\"\n",
    "\n",
    "assert_sim_1 = w2v.similarity('apple','jeep')\n",
    "assert_sim_2 = w2v.similarity('banana','jeep')\n",
    "\n",
    "assert np.isclose(assert_sim_1, sim_1, rtol=1e-05), \"Is your sim_1 value correct?\"\n",
    "assert np.isclose(assert_sim_2, sim_2, rtol=1e-05), \"Is your sim_2 value correct?\"\n",
    "\n",
    "assert_analogy = w2v.most_similar(positive=['sega', 'nintendo'], negative=['sonic'])\n",
    "\n",
    "\n",
    "assert len(assert_analogy) == len(analogy), \"Do your analogy results have the same length?\"\n",
    "for (word1, score1), (word2, score2) in zip(assert_analogy, analogy):\n",
    "    assert word1 == word2, \"Are your analogy words in the correct order?\"\n",
    "    assert np.isclose(score1, score2, rtol=1e-05), \"Are your analogy scores correct?\"\n",
    "\n",
    "print('Your code is correct!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
